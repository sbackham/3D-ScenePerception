# 3D Scene Perception using DCNNS for autonomous driving applications

## Overview
This project develops advanced techniques for 3D scene perception using a combination of Neural Radiance Fields (NeRFs) and Deep Convolutional Neural Networks (DCNNs). The goal is to enhance capabilities in digital scene reconstruction and object detection, suitable for applications in areas such as autonomous navigation and cultural heritage preservation.

## Inspiration
This work was heavily inspired by the techniques discussed in the paper "3D Bounding Box Estimation Using Deep Learning and Geometry" by Mousavian et al. While our implementation does not directly copy any code, the conceptual foundations laid by this paper guided the development of our methods. For more details on the original paper, visit [this link](https://arxiv.org/abs/1612.00496).

## Features
- **Object Detection**: Utilizes DCNNs for dynamic and accurate object detection.
- **Scene Reconstruction**: Employs NeRFs for photorealistic rendering of 3D scenes.
- **Optimization**: Techniques such as model pruning and quantization to enhance performance and efficiency.

## Installation
Instructions to set up the project environment:
```bash
pip install numpy opencv-python torch torchvision
```

## Usage
To use this project, simply clone the repository and run the Jupyter notebook provided. The notebook contains all necessary code for training and evaluating the models.

```bash
git clone https://github.com/sbackham/3D-ScenePerception.git
cd 3D-ScenePerception
jupyter notebook MAX_SIRENA_3D_CNN_BOUNDBOX_ML_P1.ipynb
```






![AMLChart](https://github.com/sbackham/3D-ScenePerception/assets/91488129/13a18671-438b-4365-b194-524c5bb96b2b)
![AMLChart](https://github.com/sbackham/3D-ScenePerception/assets/91488129/d45a82a6-80fc-4c5b-9161-8f838542a8f8)

